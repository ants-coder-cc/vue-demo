为什么在JavaScript中0.1+0.2不等于0.3？
0.1+0.2不等于0.3？是不是有点颠覆你的认知，但是，在js中，是真实存在的！

console.log(0.1+0.2);  // 0.30000000000000004
其实这都是因为浮点数运算的精度问题。

简单来说，因为计算机只认识二进制，在进行运算时，需要将其他进制的数值转换成二进制，然后再进行计算。

由于浮点数用二进制表达时是无穷的：

// 将0.1转换成二进制
console.log(0.1.toString(2)); // 0.0001100110011001100110011001100110011001100110011001101

// 将0.2转换成二进制
console.log(0.2.toString(2));  // 0.001100110011001100110011001100110011001100110011001101
IEEE 754 标准的 64 位双精度浮点数的小数部分最多支持53位二进制位，所以两者相加后，因浮点数小数位的限制而截断的二进制数字，再转换为十进制，就成了 0.30000000000000004，所以在进行算术计算时会产生误差。

64位比特又可分为三个部分：

符号位S：第 1 位是正负数符号位（sign），0代表正数，1代表负数
指数位E：中间的 11 位存储指数（exponent），用来表示次方数
尾数位M：最后的 52 位是尾数（mantissa），超出的部分自动进一舍零